{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, SpatialDropout1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数: 25000\n",
      "测试集样本数: 25000\n"
     ]
    }
   ],
   "source": [
    "def load_imdb_data(data_dir, subset='train'):\n",
    "    \"\"\"\n",
    "    从IMDB aclImdb目录中读取文本和标签。\n",
    "    subset: 'train' or 'test'\n",
    "    返回: (texts, labels)\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    # pos 文件夹\n",
    "    pos_dir = os.path.join(data_dir, subset, 'pos')\n",
    "    for fname in os.listdir(pos_dir):\n",
    "        with open(os.path.join(pos_dir, fname), 'r', encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append(1)  # 正面影评\n",
    "\n",
    "    # neg 文件夹\n",
    "    neg_dir = os.path.join(data_dir, subset, 'neg')\n",
    "    for fname in os.listdir(neg_dir):\n",
    "        with open(os.path.join(neg_dir, fname), 'r', encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append(0)  # 负面影评\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "def basic_preprocess(text):\n",
    "    \"\"\"\n",
    "    对文本做一个简单的清洗示例: 去除HTML标签、非字母字符等。\n",
    "    也可以根据需要进行更高级的清洗或分词。\n",
    "    \"\"\"\n",
    "    # 去除 HTML 标签\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    # 只保留字母和空格\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    # 转小写\n",
    "    text = text.lower()\n",
    "    # 去除多余空格\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "data_dir = \"/Volumes/Dreamer1.6/homework/大数据/aclImdb\" \n",
    "\n",
    "train_texts_raw, train_labels = load_imdb_data(data_dir, subset='train')\n",
    "test_texts_raw, test_labels = load_imdb_data(data_dir, subset='test')\n",
    "\n",
    "# 基本预处理\n",
    "train_texts = [basic_preprocess(t) for t in train_texts_raw]\n",
    "test_texts = [basic_preprocess(t) for t in test_texts_raw]\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"训练集样本数:\", len(train_texts))\n",
    "print(\"测试集样本数:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 训练集维度:  (25000, 70000)\n",
      "TF-IDF 测试集维度:  (25000, 70000)\n"
     ]
    }
   ],
   "source": [
    "# 初始化TfidfVectorizer，可以自定义token_pattern、ngram_range、max_features等超参数\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=70000,  # 取词表最大维度，可根据内存或性能需求调整\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_texts)\n",
    "X_test_tfidf = tfidf.transform(test_texts)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(\"TF-IDF 训练集维度: \", X_train_tfidf.shape)\n",
    "print(\"TF-IDF 测试集维度: \", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        20001     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93147D-01    |proj g|=  5.38894D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "20001     23     26      1     0     0   3.766D-05   3.394D-01\n",
      "  F =  0.33936644771636248     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "逻辑回归测试集准确率: 0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=200, verbose=1)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "lr_preds = lr_model.predict(X_test_tfidf)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "\n",
    "print(\"逻辑回归测试集准确率: {:.4f}\".format(lr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].................*........*\n",
      "optimization finished, #iter = 25944\n",
      "obj = -5781.909920, rho = -0.037240\n",
      "nSV = 10536, nBSV = 5866\n",
      "Total nSV = 10536\n",
      "SVM 测试集准确率: 0.8727\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', verbose=1)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "svm_preds = svm_model.predict(X_test_tfidf)\n",
    "svm_acc = accuracy_score(y_test, svm_preds)\n",
    "\n",
    "print(\"SVM 测试集准确率: {:.4f}\".format(svm_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集序列矩阵维度: (25000, 100)\n",
      "测试集序列矩阵维度: (25000, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 138ms/step - accuracy: 0.6434 - loss: 0.6101 - val_accuracy: 0.8196 - val_loss: 0.4109\n",
      "Epoch 2/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 170ms/step - accuracy: 0.8643 - loss: 0.3405 - val_accuracy: 0.8452 - val_loss: 0.3909\n",
      "Epoch 3/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 164ms/step - accuracy: 0.9061 - loss: 0.2490 - val_accuracy: 0.8024 - val_loss: 0.4959\n",
      "Epoch 4/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 166ms/step - accuracy: 0.9377 - loss: 0.1750 - val_accuracy: 0.8704 - val_loss: 0.3381\n",
      "Epoch 5/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 168ms/step - accuracy: 0.9537 - loss: 0.1358 - val_accuracy: 0.8212 - val_loss: 0.6576\n",
      "Epoch 6/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 165ms/step - accuracy: 0.9652 - loss: 0.1041 - val_accuracy: 0.8656 - val_loss: 0.4865\n",
      "Epoch 7/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 167ms/step - accuracy: 0.9732 - loss: 0.0765 - val_accuracy: 0.7576 - val_loss: 0.8827\n",
      "Epoch 8/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 167ms/step - accuracy: 0.9816 - loss: 0.0538 - val_accuracy: 0.7780 - val_loss: 1.0428\n",
      "Epoch 9/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 168ms/step - accuracy: 0.9886 - loss: 0.0367 - val_accuracy: 0.7996 - val_loss: 0.7741\n",
      "Epoch 10/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 168ms/step - accuracy: 0.9888 - loss: 0.0391 - val_accuracy: 0.8144 - val_loss: 0.8994\n",
      "Epoch 11/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 171ms/step - accuracy: 0.9924 - loss: 0.0233 - val_accuracy: 0.7776 - val_loss: 1.1326\n",
      "Epoch 12/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 169ms/step - accuracy: 0.9935 - loss: 0.0223 - val_accuracy: 0.7920 - val_loss: 1.1864\n",
      "Epoch 13/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 170ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.7920 - val_loss: 0.9831\n",
      "Epoch 14/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 172ms/step - accuracy: 0.9936 - loss: 0.0192 - val_accuracy: 0.8024 - val_loss: 1.2743\n",
      "Epoch 15/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 172ms/step - accuracy: 0.9954 - loss: 0.0146 - val_accuracy: 0.7912 - val_loss: 0.9895\n",
      "Epoch 16/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 171ms/step - accuracy: 0.9928 - loss: 0.0209 - val_accuracy: 0.8040 - val_loss: 1.0506\n",
      "Epoch 17/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 173ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.7880 - val_loss: 1.2447\n",
      "Epoch 18/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 175ms/step - accuracy: 0.9968 - loss: 0.0109 - val_accuracy: 0.8056 - val_loss: 1.0381\n",
      "Epoch 19/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.8080 - val_loss: 1.3046\n",
      "Epoch 20/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 180ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.8304 - val_loss: 1.1966\n",
      "优化后LSTM测试集准确率: 0.7778\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # 词汇表大小\n",
    "maxlen = 100        # 每条评论最长取多少个词\n",
    "embedding_dim = 128 # Embedding维度\n",
    "lstm_units = 128    # LSTM隐藏单元数\n",
    "\n",
    "# Tokenizer序列化\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "# 序列填充\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(\"训练集序列矩阵维度:\", X_train_pad.shape)\n",
    "print(\"测试集序列矩阵维度:\", X_test_pad.shape)\n",
    "\n",
    "# 模型结构优化\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(SpatialDropout1D(0.2))  # 加入空间Dropout减少过拟合\n",
    "model.add(Bidirectional(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2)))  # 改进的关键点\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "epochs = 20  \n",
    "batch_size = 128\n",
    "\n",
    "model.fit(X_train_pad, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "# 模型评估\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(\"优化后LSTM测试集准确率: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
